<?xml version="1.0" encoding="UTF-8" ?>

<chapter xml:id="ch11-hypothesis-testing-randomization" xmlns:xi="http://www.w3.org/2001/XInclude">
  <title>Hypothesis testing with randomization</title>
  
  <introduction>
    <p>Statistical inference is primarily concerned with understanding and quantifying the uncertainty of parameter estimates. While the equations and details change depending on the setting, the foundations for inference are the same throughout all of statistics.</p>
    <p>We start with two case studies designed to motivate the process of making decisions about research claims. We formalize the process through the introduction of the <alert>hypothesis testing framework</alert>, which allows us to formally evaluate claims about the population.</p>
  </introduction>

  <p>Throughout the book so far, you have worked with data in a variety of contexts. You have learned how to summarize and visualize the data as well as how to model multiple variables at the same time. Sometimes the dataset at hand represents the entire research question. But more often than not, the data have been collected to answer a research question about a larger group of which the data are a (hopefully) representative subset.</p>

  <p>You may agree that there is almost always variability in data <mdash /> one dataset will not be identical to a second dataset even if they are both collected from the same population using the same methods. However, quantifying the variability in the data is neither obvious nor easy to do, i.e., answering the question <q>how different is one dataset from another?</q> is not trivial.</p>

  <p>First, a note on notation. We generally use <m>p</m> to denote a population proportion and <m>\hat{p}</m> to denote a sample proportion. Similarly, we generally use <m>\mu</m> to denote a population mean and <m>\bar{x}</m> to denote a sample mean.</p>

  <example>
    <statement>
      <p>Suppose your professor splits the students in your class into two groups: students who sit on the left side of the classroom and students who sit on the right side of the classroom. If <m>\hat{p}_{L}</m> represents the proportion of students who prefer to read books on screen who sit on the left side of the classroom and <m>\hat{p}_{R}</m> represents the proportion of students who prefer to read books on screen who sit on the right side of the classroom, would you be surprised if <m>\hat{p}_{L}</m> did not <em>exactly</em> equal <m>\hat{p}_{R}</m>?</p>
    </statement>
    <solution>
      <p>While the proportions <m>\hat{p}_{L}</m> and <m>\hat{p}_{R}</m> would probably be close to each other, it would be unusual for them to be exactly the same. We would probably observe a small difference due to <em>chance</em>.</p>
    </solution>
  </example>

  <exercise>
    <title>Guided Practice</title>
    <statement>
      <p>If we do not think the side of the room a person sits on in class is related to whether they prefer to read books on screen, what assumption are we making about the relationship between these two variables?</p>
    </statement>
    <solution>
      <p>We would be assuming that these two variables are <alert>independent</alert>.</p>
    </solution>
  </exercise>

  <p>Studying randomness of this form is a key focus of statistics. Throughout this chapter, and those that follow, we provide three different approaches for quantifying the variability inherent in data: randomization, bootstrapping, and mathematical models. Using the methods provided in this chapter, we will be able to draw conclusions beyond the dataset at hand to research questions about larger populations that the samples come from.</p>

  <p>The first type of variability we will explore comes from experiments where the explanatory variable (or treatment) is randomly assigned to the observational units. As you learned in <xref ref="sec-data-hello" />, a randomized experiment can be used to assess whether one variable (the explanatory variable) causes changes in a second variable (the response variable). Every dataset has some variability in it, so to decide whether the variability in the data is due to (1) the causal mechanism (the randomized explanatory variable in the experiment) or instead (2) natural variability inherent to the data, we set up a sham randomized experiment as a comparison. That is, we assume that each observational unit would have gotten the exact same response value regardless of the treatment level. By reassigning the treatments many many times, we can compare the actual experiment to the sham experiment. If the actual experiment has more extreme results than any of the sham experiments, we are led to believe that it is the explanatory variable which is causing the result and not just variability inherent to the data. Using a few different case studies, let's look more carefully at this idea of a <alert>randomization test</alert>.</p>

<section xml:id="sec-caseStudySexDiscrimination">
  <title>Sex discrimination case study</title>

  <p>We consider a study investigating sex discrimination in the 1970s, which is set in the context of personnel decisions within a bank. The research question we hope to answer is, <q>Are individuals who identify as female discriminated against in promotion decisions made by their managers who identify as male?</q> <xref ref="biblio-Rosen-1974" /></p>

  <note>
    <title>Data</title>
    <p>The <url href="http://openintrostat.github.io/openintro/reference/sex_discrimination.html"><c>sex_discrimination</c></url> data can be found in the <url href="http://openintrostat.github.io/openintro"><alert>openintro</alert></url> R package.</p>
  </note>

  <p>This study considered sex roles, and only allowed for options of <q>male</q> and <q>female</q>. We should note that the identities being considered are not gender identities and that the study allowed only for a binary classification of sex.</p>

  <subsection xml:id="subsec-sex-discrimination-observed">
    <title>Observed data</title>

    <p>The participants in this study were 48 bank supervisors who identified as male, attending a management institute at the University of North Carolina in 1972. They were asked to assume the role of the personnel director of a bank and were given a personnel file to judge whether the person should be promoted to a branch manager position. The files given to the participants were identical, except that half of them indicated the candidate identified as male and the other half indicated the candidate identified as female. These files were randomly assigned to the bank managers.</p>

    <exercise>
      <title>Guided Practice</title>
      <statement>
        <p>Is this an observational study or an experiment? How does the type of study impact what can be inferred from the results?</p>
      </statement>
      <solution>
        <p>The study is an experiment, as subjects were randomly assigned a <q>male</q> file or a <q>female</q> file (remember, all the files were actually identical in content). Since this is an experiment, the results can be used to evaluate a causal relationship between the sex of a candidate and the promotion decision.</p>
      </solution>
    </exercise>

    <p>For each supervisor both the sex associated with the assigned file and the promotion decision were recorded. Using the results of the study summarized in <xref ref="tbl-sex-discrimination-obs" />, we would like to evaluate if individuals who identify as female are unfairly discriminated against in promotion decisions. In this study, a smaller proportion of female identifying applications were promoted than males (0.583 versus 0.875), but it is unclear whether the difference provides <em>convincing evidence</em> that individuals who identify as female are unfairly discriminated against.</p>

    <table xml:id="tbl-sex-discrimination-obs">
      <title>Summary results for the sex discrimination study</title>
      <tabular halign="center">
        <row header="yes" bottom="minor">
          <cell></cell>
          <cell colspan="2">decision</cell>
          <cell></cell>
        </row>
        <row header="yes" bottom="medium">
          <cell>sex</cell>
          <cell>promoted</cell>
          <cell>not promoted</cell>
          <cell>Total</cell>
        </row>
        <row>
          <cell>male</cell>
          <cell>21</cell>
          <cell>3</cell>
          <cell>24</cell>
        </row>
        <row>
          <cell>female</cell>
          <cell>14</cell>
          <cell>10</cell>
          <cell>24</cell>
        </row>
        <row bottom="medium">
          <cell>Total</cell>
          <cell>35</cell>
          <cell>13</cell>
          <cell>48</cell>
        </row>
      </tabular>
    </table>

    <p>The data are visualized in <xref ref="fig-sex-rand-obs" /> as a set of cards. Note that each card denotes a personnel file (an observation from our dataset) and the colors indicate the decision: red for promoted and white for not promoted. Additionally, the observations are broken up into groups of male and female identifying groups.</p>

    <figure xml:id="fig-sex-rand-obs">
      <caption>The sex discrimination study can be thought of as 48 red and white cards.</caption>
      <image source="images/sex-rand-01-obs.png" width="35%" />
    </figure>

    <example>
      <statement>
        <p>Statisticians are sometimes called upon to evaluate the strength of evidence. When looking at the rates of promotion in this study, why might we be tempted to immediately conclude that individuals identifying as female are being discriminated against?</p>
      </statement>
      <solution>
        <p>The large difference in promotion rates (58.3% for female personnel versus 87.5% for male personnel) suggests there might be discrimination against women in promotion decisions. However, we cannot yet be sure if the observed difference represents discrimination or is just due to random chance when there is no discrimination occurring. Since we wouldn't expect the sample proportions to be <em>exactly</em> equal, even if the truth was that the promotion decisions were independent of sex, we can't rule out random chance as a possible explanation when simply comparing the sample proportions.</p>
      </solution>
    </example>

    <p>The previous example is a reminder that there will always be variability in data (making the groups differ), even if there are no underlying causes for that difference (e.g., even if there is no discrimination). <xref ref="tbl-sex-discrimination-obs" /> shows there were 7 fewer promotions for female identifying personnel than for the male personnel, a difference in promotion rates of 29.2% <m>\left( \frac{21}{24} - \frac{14}{24} = 0.292 \right).</m> This observed difference is what we call a <alert>point estimate</alert> of the true difference. The point estimate of the difference in promotion rate is large, but the sample size for the study is small, making it unclear if the observed difference represents discrimination or is simply due to chance. Chance can be thought of as the claim due to natural variability; discrimination can be thought of as the claim the researchers set out to demonstrate. We label these two competing claims, <m>H_0</m> and <m>H_A:</m></p>

    <p><ul>
      <li><m>H_0:</m> <alert>Null hypothesis</alert>. The variables <c>sex</c> and <c>decision</c> are independent. The difference in promotion rates of 29.2% was due to natural variability inherent in the population.</li>
      <li><m>H_A:</m> <alert>Alternative hypothesis</alert>. The variables <c>sex</c> and <c>decision</c> are <em>not</em> independent. The difference in promotion rates of 29.2% was not due to natural variability, and equally qualified female personnel are less likely to be promoted than male personnel.</li>
    </ul></p>

    <note>
      <title>Important</title>
      <p><alert>Hypothesis testing.</alert></p>
      <p>These hypotheses are part of what is called a <alert>hypothesis test</alert>. A hypothesis test is a statistical technique used to evaluate competing claims using data. Often times, the null hypothesis takes a stance of <em>no difference</em> or <em>no effect</em>. This hypothesis assumes that any differences observed are due to the variability inherent in the population and could have occurred by random chance.</p>
      <p>If the null hypothesis and the data notably disagree, then we reject the null hypothesis in favor of the alternative hypothesis.</p>
      <p>There are many nuances to hypothesis testing, so do not worry if you don't feel like a master of hypothesis testing at the end of this section. We'll discuss these ideas and details many times in this chapter as well as in the chapters that follow.</p>
    </note>

    <p>What would it mean if the null hypothesis, which says the variables <c>sex</c> and <c>decision</c> are unrelated, was true? It would mean each banker would decide whether to promote the candidate without regard to the sex indicated on the personnel file. That is, the difference in the promotion percentages would be due to the natural variability in how the files were randomly allocated to different bankers, and this randomization just happened to give rise to a relatively large difference of 29.2%.</p>

    <p>Consider the alternative hypothesis: bankers were influenced by which sex was listed on the personnel file. If this was true, and especially if this influence was substantial, we would expect to see some difference in the promotion rates of male and female candidates. If this sex bias was against female candidates, we would expect a smaller fraction of promotion recommendations for female personnel relative to the male personnel.</p>

    <p>We will choose between the two competing claims by assessing if the data conflict so much with <m>H_0</m> that the null hypothesis cannot be deemed reasonable. If data and the null claim seem to be at odds with one another, and the data seem to support <m>H_A,</m> then we will reject the notion of independence and conclude that the data provide evidence of discrimination.</p>
  </subsection>

  <subsection xml:id="subsec-sex-discrimination-variability">
    <title>Variability of the statistic</title>

    <p><xref ref="tbl-sex-discrimination-obs" /> shows that 35 bank supervisors recommended promotion and 13 did not. Now, suppose the bankers' decisions were independent of the sex of the candidate. Then, if we conducted the experiment again with a different random assignment of sex to the files, differences in promotion rates would be based only on random fluctuation in promotion decisions. We can perform this <alert>randomization</alert>, which simulates what would have happened if the bankers' decisions had been independent of <c>sex</c> but we had distributed the file sexes differently.<fn>This procedure is formally called a <alert>permutation test</alert>.</fn></p>

    <p>In the <alert>simulation</alert>, we thoroughly shuffle the 48 personnel files, 35 labelled <c>promoted</c> and 13 labelled <c>not promoted</c>, together and we deal files into two new stacks. Note that by keeping 35 promoted and 13 not promoted, we are assuming that 35 of the bank managers would have promoted the individual whose content is contained in the file <alert>independent</alert> of the sex indicated on their file. We will deal 24 files into the first stack, which will represent the 24 <q>female</q> files. The second stack will also have 24 files, and it will represent the 24 <q>male</q> files. <xref ref="fig-sex-rand-shuffle-1" /> highlights both the shuffle and the reallocation to the sham sex groups.</p>

    <figure xml:id="fig-sex-rand-shuffle-1">
      <caption>The sex discrimination data are shuffled and reallocated to new groups of male and female files.</caption>
      <image source="images/sex-rand-02-shuffle-1.png" width="75%" />
    </figure>

    <p>Then, as we did with the original data, we tabulate the results and determine the fraction of personnel files designated as <q>male</q> and <q>female</q> who were promoted.</p>

    <p>Since the randomization of files in this simulation is independent of the promotion decisions, any difference in promotion rates is due to chance. <xref ref="tbl-sex-discrimination-rand-1" /> shows the results of one such simulation.</p>

    <table xml:id="tbl-sex-discrimination-rand-1">
      <title>Simulation results, where the difference in promotion rates between male and female is purely due to random chance</title>
      <tabular halign="center">
        <row header="yes" bottom="minor">
          <cell></cell>
          <cell colspan="2">decision</cell>
          <cell></cell>
        </row>
        <row header="yes" bottom="medium">
          <cell>sex</cell>
          <cell>promoted</cell>
          <cell>not promoted</cell>
          <cell>Total</cell>
        </row>
        <row>
          <cell>male</cell>
          <cell>18</cell>
          <cell>6</cell>
          <cell>24</cell>
        </row>
        <row>
          <cell>female</cell>
          <cell>17</cell>
          <cell>7</cell>
          <cell>24</cell>
        </row>
        <row bottom="medium">
          <cell>Total</cell>
          <cell>35</cell>
          <cell>13</cell>
          <cell>48</cell>
        </row>
      </tabular>
    </table>

    <exercise>
      <title>Guided Practice</title>
      <statement>
        <p>What is the difference in promotion rates between the two simulated groups in <xref ref="tbl-sex-discrimination-rand-1" />? How does this compare to the observed difference 29.2% from the actual study?</p>
      </statement>
      <solution>
        <p><m>18/24 - 17/24 = 0.042</m> or about 4.2% in favor of the male personnel. This difference due to chance is much smaller than the difference observed in the actual groups.</p>
      </solution>
    </exercise>

    <p><xref ref="fig-sex-rand-shuffle-1-sort" /> shows that the difference in promotion rates is much larger in the original data than it is in the simulated groups (0.292 &gt; 0.042). The quantity of interest throughout this case study has been the difference in promotion rates. We call the summary value the <alert>statistic</alert> of interest (or often the <alert>test statistic</alert>). When we encounter different data structures, the statistic is likely to change (e.g., we might calculate an average instead of a proportion), but we will always want to understand how the statistic varies from sample to sample.</p>

    <figure xml:id="fig-sex-rand-shuffle-1-sort">
      <caption>We summarize the randomized data to produce one estimate of the difference in proportions given no sex discrimination. Note that the sort step is only used to make it easier to visually calculate the simulated sample proportions.</caption>
      <image source="images/sex-rand-03-shuffle-1-sort.png" width="100%" />
    </figure>
  </subsection>

  <subsection xml:id="subsec-sex-discrimination-null-stats">
    <title>Observed statistic vs. null statistics</title>

    <p>We computed one possible difference under the null hypothesis in Guided Practice, which represents one difference due to chance when the null hypothesis is assumed to be true. While in this first simulation, we physically dealt out files, it is much more efficient to perform this simulation using a computer. Repeating the simulation on a computer, we get another difference due to chance under the same assumption: -0.042. And another: 0.208. And so on until we repeat the simulation enough times that we have a good idea of the shape of the <em>distribution of differences</em> under the null hypothesis. <xref ref="fig-sex-rand-dot-plot" /> shows a plot of the differences found from 100 simulations, where each dot represents a simulated difference between the proportions of male and female files recommended for promotion.</p>

    <listing xml:id="listing-sex-rand-dot-plot">
      <caption>R code to generate 100 simulated differences under the null hypothesis</caption>
      <program language="r">
        <code>
set.seed(37)
sex_discrimination |&gt;
  specify(decision ~ sex, success = "promoted") |&gt;
  hypothesize(null = "independence") |&gt;
  generate(reps = 100, type = "permute") |&gt;
  calculate(stat = "diff in props", order = c("male", "female")) |&gt;
  mutate(stat = round(stat, 3)) |&gt;
  ggplot(aes(x = stat)) +
  geom_dotplot(binwidth = 0.01) +
  gghighlight(stat &gt;= 0.292) +
  theme(
    axis.ticks.y = element_blank(),
    axis.text.y = element_blank()
  ) +
  labs(
    x = "Differences in promotion rates (male - female) across many shuffles",
    y = NULL
  )
        </code>
      </program>
    </listing>

    <figure xml:id="fig-sex-rand-dot-plot">
      <caption>A stacked dot plot of differences from 100 simulations produced under the null hypothesis, <m>H_0,</m> where the simulated sex and decision are independent. Two of the 100 simulations had a difference of at least 29.2%, the difference observed in the study, and are shown as solid blue dots.</caption>
      <image source="images/fig-sex-rand-dot-plot-1.png" width="70%" />
    </figure>

    <p>Note that the distribution of these simulated differences in proportions is centered around 0. Under the null hypothesis our simulations made no distinction between male and female personnel files. Thus, a center of 0 makes sense: we should expect differences from chance alone to fall around zero with some random fluctuation for each simulation.</p>

    <example>
      <statement>
        <p>How often would you observe a difference of at least 29.2% (0.292) according to <xref ref="fig-sex-rand-dot-plot" />? Often, sometimes, rarely, or never?</p>
      </statement>
      <solution>
        <p>It appears that a difference of at least 29.2% under the null hypothesis would only happen about 2% of the time according to <xref ref="fig-sex-rand-dot-plot" />. Such a low probability indicates that observing such a large difference from chance alone is rare.</p>
      </solution>
    </example>

    <p>The difference of 29.2% is a rare event if there really is no impact from listing sex in the candidates' files, which provides us with two possible interpretations of the study results:</p>

    <p><ul>
      <li>If <m>H_0,</m> the <alert>Null hypothesis</alert> is true: Sex has no effect on promotion decision, and we observed a difference that is so large that it would only happen rarely.</li>
      <li>If <m>H_A,</m> the <alert>Alternative hypothesis</alert> is true: Sex has an effect on promotion decision, and what we observed was actually due to equally qualified female candidates being discriminated against in promotion decisions, which explains the large difference of 29.2%.</li>
    </ul></p>

    <p>When we conduct formal studies, we reject a null position (the idea that the data are a result of chance only) if the data strongly conflict with that null position.<fn>This reasoning does not generally extend to anecdotal observations. Each of us observes incredibly rare events every day, events we could not possibly hope to predict. However, in the non-statistical setting, we should be cautious not to overinterpret such anecdotal evidence. In our daily lives, we should make decisions and reach conclusions based on evidence that is not only rare, but also trustworthy. Anecdotal evidence typically is not trustworthy evidence.</fn> In our analysis, we determined that there was only a <m>\approx</m> 2% probability of obtaining a sample where <m>\geq</m> 29.2% more male candidates than female candidates get promoted under the null hypothesis, so we conclude that the data provide strong evidence of sex discrimination against female candidates by the male supervisors. In this case, we reject the null hypothesis in favor of the alternative.</p>

    <p><alert>Statistical inference</alert> is the practice of making decisions and conclusions from data in the context of uncertainty. Errors do occur, just like rare events, and the dataset at hand might lead us to the wrong conclusion. While a given dataset may not always lead us to a correct conclusion, statistical inference gives us tools to control and evaluate how often these errors occur. Before getting into the nuances of hypothesis testing, let's work through another case study.</p>
  </subsection>
</section>

<section xml:id="sec-caseStudyOpportunityCost">
  <title>Opportunity cost case study</title>

  <p>How rational and consistent is the behavior of the typical American college student? In this section, we'll explore whether college student consumers always consider the following: money not spent now can be spent later.</p>

  <p>In particular, we are interested in whether reminding students about this well-known fact about money causes them to be a little thriftier. A skeptic might think that such a reminder would have no impact. We can summarize the two different perspectives using the null and alternative hypothesis framework.</p>

  <p><ul>
    <li><m>H_0:</m> <alert>Null hypothesis</alert>. Reminding students that they can save money for later purchases will not have any impact on students' spending decisions.</li>
    <li><m>H_A:</m> <alert>Alternative hypothesis</alert>. Reminding students that they can save money for later purchases will reduce the chance they will continue with a purchase.</li>
  </ul></p>

  <p>In this section, we'll explore an experiment conducted by researchers that investigates this very question for students at a university in the southwestern United States. <xref ref="biblio-Frederick-2009" /></p>

  <subsection xml:id="subsec-opportunity-cost-observed">
    <title>Observed data</title>

    <p>One-hundred and fifty students were recruited for the study, and each was given the following statement:</p>

    <blockquote>
      <p><em>Imagine that you have been saving some extra money on the side to make some purchases, and on your most recent visit to the video store you come across a special sale on a new video. This video is one with your favorite actor or actress, and your favorite type of movie (such as a comedy, drama, thriller, etc.). This particular video that you are considering is one you have been thinking about buying for a long time. It is available for a special sale price of $14.99. What would you do in this situation? Please circle one of the options below.</em><fn>Notice that the study was conducted in the mid-2000s. At that time, video stores were still common and the price of a video was about $15. While these details may be dated, the results of the study are still relevant.</fn></p>
    </blockquote>

    <p>Half of the 150 students were randomized into a control group and were given the following two options:</p>

    <blockquote>
      <p>(A) Buy this entertaining video.</p>
      <p>(B) Not buy this entertaining video.</p>
    </blockquote>

    <p>The remaining 75 students were placed in the treatment group, and they saw a slightly modified option (B):</p>

    <blockquote>
      <p>(A) Buy this entertaining video.</p>
      <p>(B) Not buy this entertaining video. Keep the $14.99 for other purchases.</p>
    </blockquote>

    <p>Would the extra statement reminding students of an obvious fact impact the purchasing decision? <xref ref="tbl-opportunity-cost-obs" /> summarizes the study results.</p>

    <note>
      <title>Data</title>
      <p>The <url href="http://openintrostat.github.io/openintro/reference/opportunity_cost.html"><c>opportunity_cost</c></url> data can be found in the <url href="http://openintrostat.github.io/openintro"><alert>openintro</alert></url> R package.</p>
    </note>

    <table xml:id="tbl-opportunity-cost-obs">
      <title>Summary results of the opportunity cost study</title>
      <tabular halign="center">
        <row header="yes" bottom="minor">
          <cell></cell>
          <cell colspan="2">decision</cell>
          <cell></cell>
        </row>
        <row header="yes" bottom="medium">
          <cell>group</cell>
          <cell>buy video</cell>
          <cell>not buy video</cell>
          <cell>Total</cell>
        </row>
        <row>
          <cell>control</cell>
          <cell>56</cell>
          <cell>19</cell>
          <cell>75</cell>
        </row>
        <row>
          <cell>treatment</cell>
          <cell>41</cell>
          <cell>34</cell>
          <cell>75</cell>
        </row>
        <row bottom="medium">
          <cell>Total</cell>
          <cell>97</cell>
          <cell>53</cell>
          <cell>150</cell>
        </row>
      </tabular>
    </table>

    <p>It might be a little easier to review the results using a visualization. <xref ref="fig-opportunity-cost-obs-bar" /> shows that a higher proportion of students in the treatment group chose not to buy the video compared to those in the control group.</p>

    <listing xml:id="listing-opportunity-cost-obs-bar">
      <caption>R code for stacked bar plot of opportunity cost study results</caption>
      <program language="r">
        <code>
ggplot(opportunity_cost, aes(y = fct_rev(group), fill = fct_rev(decision))) +
  geom_bar(position = "fill") +
  scale_fill_openintro("two") +
  scale_x_continuous(labels = label_percent()) +
  labs(
    x = "Proportion",
    y = "Group",
    fill = "Decision"
  )
        </code>
      </program>
    </listing>

    <figure xml:id="fig-opportunity-cost-obs-bar">
      <caption>Stacked bar plot of results of the opportunity cost study.</caption>
      <image source="images/fig-opportunity-cost-obs-bar-1.png" width="70%" />
    </figure>

    <p>Another useful way to review the results from <xref ref="tbl-opportunity-cost-obs" /> is using row proportions, specifically considering the proportion of participants in each group who said they would buy or not buy the video. These summaries are given in <xref ref="tbl-opportunity-cost-obs-row-prop" />.</p>

    <table xml:id="tbl-opportunity-cost-obs-row-prop">
      <title>The opportunity cost data are summarized using row proportions. Row proportions are particularly useful here since we can view the proportion of <em>buy</em> and <em>not buy</em> decisions in each group</title>
      <tabular halign="center">
        <row header="yes" bottom="minor">
          <cell></cell>
          <cell colspan="2">decision</cell>
          <cell></cell>
        </row>
        <row header="yes" bottom="medium">
          <cell>group</cell>
          <cell>buy video</cell>
          <cell>not buy video</cell>
          <cell>Total</cell>
        </row>
        <row>
          <cell>control</cell>
          <cell>0.747</cell>
          <cell>0.253</cell>
          <cell>1.0</cell>
        </row>
        <row>
          <cell>treatment</cell>
          <cell>0.547</cell>
          <cell>0.453</cell>
          <cell>1.0</cell>
        </row>
      </tabular>
    </table>

    <p>We will define a <alert>success</alert> in this study as a student who chooses not to buy the video.<fn>Success does not necessarily mean a positive or good outcome. Here a success refers to the outcome of interest, which is a student choosing not to buy the video.</fn> Then, the value of interest is the change in video purchase rates that results by reminding students that not spending money now means they can spend the money later.</p>

    <p>We can construct a point estimate for this difference as (<m>T</m> for treatment and <m>C</m> for control):</p>

    <me>\hat{p}_{T} - \hat{p}_{C} = \frac{34}{75} - \frac{19}{75} = 0.453 - 0.253 = 0.200</me>

    <p>The proportion of students who chose not to buy the video was 20 percentage points higher in the treatment group than the control group. Is this 20% difference between the two groups so prominent that it is unlikely to have occurred from chance alone, if there is no difference between the spending habits of the two groups?</p>
  </subsection>

  <subsection xml:id="subsec-opportunity-cost-variability">
    <title>Variability of the statistic</title>

    <p>The primary goal in this data analysis is to understand what sort of differences we might see if the null hypothesis were true, i.e., the treatment had no effect on students. Because this is an experiment, we'll use the same procedure we applied in <xref ref="sec-caseStudySexDiscrimination" />: randomization.</p>

    <p>Let's think about the data in the context of the hypotheses. If the null hypothesis <m>(H_0)</m> was true and the treatment had no impact on student decisions, then the observed difference between the two groups of 20% could be attributed entirely to random chance. If, on the other hand, the alternative hypothesis <m>(H_A)</m> is true, then the difference indicates that reminding students about saving for later purchases actually impacts their buying decisions.</p>
  </subsection>

  <subsection xml:id="subsec-opportunity-cost-null-stats">
    <title>Observed statistic vs. null statistics</title>

    <p>Just like with the sex discrimination study, we can perform a statistical analysis. Using the same randomization technique from the last section, let's see what happens when we simulate the experiment under the scenario where there is no effect from the treatment.</p>

    <p>While we would in reality do this simulation on a computer, it might be useful to think about how we would go about carrying out the simulation without a computer. We start with 150 index cards and label each card to indicate the distribution of our response variable: <c>decision</c>. That is, 53 cards will be labeled <q>not buy video</q> to represent the 53 students who opted not to buy, and 97 will be labeled <q>buy video</q> for the other 97 students. Then we shuffle these cards thoroughly and divide them into two stacks of size 75, representing the simulated treatment and control groups. Because we have shuffled the cards from both groups together, assuming no difference in their purchasing behavior, any observed difference between the proportions of <q>not buy video</q> cards (what we earlier defined as <em>success</em>) can be attributed entirely to chance.</p>

    <example>
      <statement>
        <p>If we are randomly assigning the cards into the simulated treatment and control groups, how many <q>not buy video</q> cards would we expect to end up in each simulated group? What would be the expected difference between the proportions of <q>not buy video</q> cards in each group?</p>
      </statement>
      <solution>
        <p>Since the simulated groups are of equal size, we would expect <m>53 / 2 = 26.5,</m> i.e., 26 or 27, <q>not buy video</q> cards in each simulated group, yielding a simulated point estimate of the difference in proportions of 0%. However, due to random chance, we might also expect to sometimes observe a number a little above or below 26 and 27.</p>
      </solution>
    </example>

    <p>The results of a single randomization is shown in <xref ref="tbl-opportunity-cost-obs-simulated" />.</p>

    <table xml:id="tbl-opportunity-cost-obs-simulated">
      <title>Summary of student choices against their simulated groups. The group assignment had no connection to the student decisions, so any difference between the two groups is due to chance</title>
      <tabular halign="center">
        <row header="yes" bottom="minor">
          <cell></cell>
          <cell colspan="2">decision</cell>
          <cell></cell>
        </row>
        <row header="yes" bottom="medium">
          <cell>group</cell>
          <cell>buy video</cell>
          <cell>not buy video</cell>
          <cell>Total</cell>
        </row>
        <row>
          <cell>control</cell>
          <cell>46</cell>
          <cell>29</cell>
          <cell>75</cell>
        </row>
        <row>
          <cell>treatment</cell>
          <cell>51</cell>
          <cell>24</cell>
          <cell>75</cell>
        </row>
        <row bottom="medium">
          <cell>Total</cell>
          <cell>97</cell>
          <cell>53</cell>
          <cell>150</cell>
        </row>
      </tabular>
    </table>

    <p>From this table, we can compute a difference that occurred from the first shuffle of the data (i.e., from chance alone):</p>

    <me>\hat{p}_{T, shfl1} - \hat{p}_{C, shfl1} = \frac{24}{75} - \frac{29}{75} = 0.32 - 0.387 = - 0.067</me>

    <p>Just one simulation will not be enough to get a sense of what sorts of differences would happen from chance alone.</p>

    <p>We'll simulate another set of simulated groups and compute the new difference: 0.04.</p>

    <p>And again: -0.013.</p>

    <p>And again: 0.04.</p>

    <p>We'll do this 1,000 times.</p>

    <p>The results are summarized in a dot plot in <xref ref="fig-opportunity-cost-rand-dot-plot" />, where each point represents the difference from one randomization.</p>

    <listing xml:id="listing-opportunity-cost-rand-dist">
      <caption>R code to generate 1,000 simulated differences under the null hypothesis</caption>
      <program language="r">
        <code>
set.seed(25)
opportunity_cost |&gt;
  specify(decision ~ group, success = "not buy video") |&gt;
  hypothesize(null = "independence") |&gt;
  generate(reps = 1000, type = "permute") |&gt;
  calculate(stat = "diff in props", order = c("treatment", "control")) |&gt;
  mutate(stat = round(stat, 3)) |&gt;
  ggplot(aes(x = stat)) +
  geom_dotplot(binwidth = 0.01, dotsize = 0.165) +
  gghighlight(stat &gt;= 0.20) +
  theme(
    axis.ticks.y = element_blank(),
    axis.text.y = element_blank()
  ) +
  labs(
    title = "1,000 differences in randomized proportions",
    x = "Difference in randomized proportions of students who\ndo not buy the video (treatment - control)",
    y = NULL
  )
        </code>
      </program>
    </listing>

    <figure xml:id="fig-opportunity-cost-rand-dot-plot">
      <caption>A stacked dot plot of 1,000 simulated (null) differences produced under the null hypothesis, <m>H_0.</m> Six of the 1,000 simulations had a difference of at least 20%, which was the difference observed in the study.</caption>
      <image source="images/fig-opportunity-cost-rand-dot-plot-1.png" width="70%" />
    </figure>

    <p>Since there are so many points and it is difficult to discern one point from the other, it is more convenient to summarize the results in a histogram such as the one in <xref ref="fig-opportunity-cost-rand-hist" />, where the height of each histogram bar represents the number of simulations resulting in an outcome of that magnitude.</p>

    <listing xml:id="listing-opportunity-cost-rand-hist">
      <caption>R code to create histogram of simulated differences</caption>
      <program language="r">
        <code>
ggplot(opportunity_cost_rand_dist, aes(x = stat)) +
  geom_histogram(binwidth = 0.04) +
  gghighlight(stat &gt;= 0.20) +
  labs(
    title = "1,000 differences in randomized proportions",
    x = "Difference in randomized proportions of students who\ndo not buy the video (treatment - control)",
    y = "Count\n(Number of simulated scenarios)"
  )
        </code>
      </program>
    </listing>

    <figure xml:id="fig-opportunity-cost-rand-hist">
      <caption>A histogram of 1,000 chance differences produced under the null hypothesis. Histograms like this one are a convenient representation of data or results when there are a large number of simulations.</caption>
      <image source="images/fig-opportunity-cost-rand-hist-1.png" width="70%" />
    </figure>

    <p>Under the null hypothesis (no treatment effect), we would observe a difference of at least +20% about 0.6% of the time. That is really rare! Instead, we will conclude the data provide strong evidence there is a treatment effect: reminding students before a purchase that they could instead spend the money later on something else lowers the chance that they will continue with the purchase. Notice that we are able to make a causal statement for this study since the study is an experiment, although we do not know why the reminder induces a lower purchase rate.</p>
  </subsection>
</section>

<section xml:id="sec-HypothesisTesting">
  <title>Hypothesis testing</title>

  <p>In the last two sections, we utilized a <alert>hypothesis test</alert>, which is a formal technique for evaluating two competing possibilities. In each scenario, we described a <alert>null hypothesis</alert>, which represented either a skeptical perspective or a perspective of no difference. We also laid out an <alert>alternative hypothesis</alert>, which represented a new perspective such as the possibility of a relationship between two variables or a treatment effect in an experiment. The alternative hypothesis is usually the reason the scientists set out to do the research in the first place.</p>

  <note>
    <title>Important</title>
    <p><alert>Null and alternative hypotheses.</alert></p>
    <p>The <alert>null hypothesis</alert> <m>(H_0)</m> often represents either a skeptical perspective or a claim of <q>no difference</q> to be tested.</p>
    <p>The <alert>alternative hypothesis</alert> <m>(H_A)</m> represents an alternative claim under consideration and is often represented by a range of possible values for the value of interest.</p>
  </note>

  <p>If a person makes a somewhat unbelievable claim, we are initially skeptical. However, if there is sufficient evidence that supports the claim, we set aside our skepticism. The hallmarks of hypothesis testing are also found in the US court system.</p>

  <subsection xml:id="subsec-us-court-system">
    <title>The US court system</title>

    <p>In the US court system, jurors evaluate the evidence to see whether it convincingly shows a defendant is guilty. Defendants are considered to be innocent until proven otherwise.</p>

    <example>
      <statement>
        <p>The US court considers two possible claims about a defendant: they are either innocent or guilty.</p>
        <p>If we set these claims up in a hypothesis framework, which would be the null hypothesis and which the alternative?</p>
      </statement>
      <solution>
        <p>The jury considers whether the evidence is so convincing (strong) that there is no reasonable doubt regarding the person's guilt. That is, the skeptical perspective (null hypothesis) is that the person is innocent until evidence is presented that convinces the jury that the person is guilty (alternative hypothesis).</p>
      </solution>
    </example>

    <p>Jurors examine the evidence to see whether it convincingly shows a defendant is guilty. Notice that if a jury finds a defendant <em>not guilty</em>, this does not necessarily mean the jury is confident in the person's innocence. They are simply not convinced of the alternative, that the person is guilty. This is also the case with hypothesis testing: <em>even if we fail to reject the null hypothesis, we do not accept the null hypothesis as truth</em>.</p>

    <p>Failing to find evidence in favor of the alternative hypothesis is not equivalent to finding evidence that the null hypothesis is true. We will see this idea in greater detail in <xref ref="sec-foundations-decision-errors" />.</p>
  </subsection>

  <subsection xml:id="subsec-p-value">
    <title>p-value and statistical discernibility</title>

    <p>In <xref ref="sec-caseStudySexDiscrimination" /> we encountered a study from the 1970's that explored whether there was strong evidence that female candidates were less likely to be promoted than male candidates. The research question <mdash /> are female candidates discriminated against in promotion decisions? <mdash /> was framed in the context of hypotheses:</p>

    <p><ul>
      <li><m>H_0:</m> Sex has no effect on promotion decisions.</li>
      <li><m>H_A:</m> Female candidates are discriminated against in promotion decisions.</li>
    </ul></p>

    <p>The null hypothesis <m>(H_0)</m> was a perspective of no difference in promotion. The data on sex discrimination provided a point estimate of a 29.2% difference in recommended promotion rates between male and female candidates. We determined that such a difference from chance alone, assuming the null hypothesis was true, would be rare: it would only happen about 2 in 100 times. When results like these are inconsistent with <m>H_0,</m> we reject <m>H_0</m> in favor of <m>H_A.</m> Here, we concluded there was discrimination against female candidates.</p>

    <p>The 2-in-100 chance is what we call a <alert>p-value</alert>, which is a probability quantifying the strength of the evidence against the null hypothesis, given the observed data.</p>

    <note>
      <title>Important</title>
      <p><alert>p-value.</alert></p>
      <p>The <alert>p-value</alert> is the probability of observing data at least as favorable to the alternative hypothesis as our current dataset, if the null hypothesis were true. We typically use a summary statistic of the data, such as a difference in proportions, to help compute the p-value and evaluate the hypotheses. This summary value that is used to compute the p-value is often called the <alert>test statistic</alert>.</p>
    </note>

    <example>
      <statement>
        <p>In the sex discrimination study, the difference in discrimination rates was our test statistic. What was the test statistic in the opportunity cost study covered in <xref ref="sec-caseStudyOpportunityCost" />?</p>
      </statement>
      <solution>
        <p>The test statistic in the opportunity cost study was the difference in the proportion of students who decided against the video purchase in the treatment and control groups. In each of these examples, the <alert>point estimate</alert> of the difference in proportions was used as the test statistic.</p>
      </solution>
    </example>

    <p>When the p-value is small, i.e., less than a previously set threshold, we say the results are <alert>statistically discernible</alert>. This means the data provide such strong evidence against <m>H_0</m> that we reject the null hypothesis in favor of the alternative hypothesis.<fn>This reasoning does not generally extend to anecdotal observations. Each of us observes incredibly rare events every day, events we could not possibly hope to predict. However, in the non-statistical setting, we should be cautious not to overinterpret such anecdotal evidence. In our daily lives, we should make decisions and reach conclusions based on evidence that is not only rare, but also trustworthy. Anecdotal evidence typically is not trustworthy evidence.</fn> The threshold is called the <alert>discernibility level</alert> and often represented by <m>\alpha</m> (the Greek letter <em>alpha</em>). <fn>This discernibility level is sometimes also referred to as the <alert>significance level</alert>, but since we are trying to move away from the term <q>statistically significant</q> we will use <q>discernibility level</q> instead.</fn> The value of <m>\alpha</m> represents how rare an event needs to be in order for the null hypothesis to be rejected. Historically, many fields have set <m>\alpha = 0.05,</m> if the null hypothesis is to be rejected. The value of <m>\alpha</m> can vary depending on the the field or the application.</p>

    <p>Note that you may have heard the phrase <q>statistically significant</q> as a way to describe <q>statistically discernible.</q> Although in everyday language <q>significant</q> would indicate that a difference is large or meaningful, that is not necessarily the case here. The term <q>statistically discernible</q> indicates that the p-value from a study fell below the chosen discernibility level. For example, in the sex discrimination study, the p-value was found to be approximately 0.02. Using a discernibility level of <m>\alpha = 0.05,</m> we would say that the data provided statistically discernible evidence against the null hypothesis. However, this conclusion gives us no information regarding the size of the difference in promotion rates!</p>

    <note>
      <title>Important</title>
      <p><alert>Statistical discernibility.</alert></p>
      <p>We say that the data provide <alert>statistically discernible</alert> evidence against the null hypothesis if the p-value is less than some predetermined threshold (e.g., 0.01, 0.05, 0.1).</p>
    </note>

    <example>
      <statement>
        <p>In the opportunity cost study in <xref ref="sec-caseStudyOpportunityCost" />, we analyzed an experiment where study participants had a 20% drop in likelihood of continuing with a video purchase if they were reminded that the money, if not spent on the video, could be used for other purchases in the future. We determined that such a large difference would only occur 6-in-1,000 times if the reminder actually had no influence on student decision-making. What is the p-value in this study? Would you classify the result as <q>statistically discernible</q>?</p>
      </statement>
      <solution>
        <p>The p-value was 0.006. Since the p-value is less than 0.05, the data provide statistically discernible evidence that US college students were actually influenced by the reminder.</p>
      </solution>
    </example>

    <note>
      <title>Important</title>
      <p><alert>What's so special about 0.05?</alert></p>
      <p>We often use a threshold of 0.05 to determine whether a result is statistically discernible. But why 0.05? Maybe we should use a bigger number, or maybe a smaller number. If you're a little puzzled, that probably means you're reading with a critical eye <mdash /> good job! We've made a video to help clarify <em>why 0.05</em>:</p>
      <p><url href="https://www.openintro.org/book/stat/why05/">https://www.openintro.org/book/stat/why05/</url></p>
      <p>Sometimes it's also a good idea to deviate from the standard. We'll discuss when to choose a threshold different than 0.05 in <xref ref="sec-foundations-decision-errors" />.</p>
    </note>
  </subsection>
</section>

<section xml:id="sec-chp11-review">
  <title>Chapter review</title>

  <subsection xml:id="subsec-chp11-summary">
    <title>Summary</title>

    <p><xref ref="fig-fullrand" /> provides a visual summary of the randomization testing procedure.</p>

    <figure xml:id="fig-fullrand">
      <caption>An example of one simulation of the full randomization procedure from a hypothetical dataset as visualized in the first panel. We repeat the steps hundreds or thousands of times.</caption>
      <image source="images/fullrand.png" width="100%" />
    </figure>

    <p>We can summarize the randomization test procedure as follows:</p>

    <p><ul>
      <li><alert>Frame the research question in terms of hypotheses.</alert> Hypothesis tests are appropriate for research questions that can be summarized in two competing hypotheses. The null hypothesis <m>(H_0)</m> usually represents a skeptical perspective or a perspective of no relationship between the variables. The alternative hypothesis <m>(H_A)</m> usually represents a new view or the existence of a relationship between the variables.</li>
      <li><alert>Collect data with an observational study or experiment.</alert> If a research question can be formed into two hypotheses, we can collect data to run a hypothesis test. If the research question focuses on associations between variables but does not concern causation, we would use an observational study. If the research question seeks a causal connection between two or more variables, then an experiment should be used.</li>
      <li><alert>Model the randomness that would occur if the null hypothesis was true.</alert> In the examples above, the variability has been modeled as if the treatment (e.g., sexual identity, opportunity) allocation was independent of the outcome of the study. The computer generated null distribution is the result of many different randomizations and quantifies the variability that would be expected if the null hypothesis was true.</li>
      <li><alert>Analyze the data.</alert> Choose an analysis technique appropriate for the data and identify the p-value. So far, we have only seen one analysis technique: randomization. Throughout the rest of this textbook, we'll encounter several new methods suitable for many other contexts.</li>
      <li><alert>Form a conclusion.</alert> Using the p-value from the analysis, determine whether the data provide evidence against the null hypothesis. Also, be sure to write the conclusion in plain language so casual readers can understand the results.</li>
    </ul></p>

    <p><xref ref="tbl-chp11-summary" /> is another look at the randomization test summary.</p>

    <table xml:id="tbl-chp11-summary">
      <title>Summary of randomization as an inferential statistical method</title>
      <tabular halign="left">
        <row header="yes" bottom="medium">
          <cell>Question</cell>
          <cell>Answer</cell>
        </row>
        <row>
          <cell>What does it do?</cell>
          <cell>Shuffles the explanatory variable to mimic the variability under the null hypothesis</cell>
        </row>
        <row>
          <cell>What is the random process described in the context of the data?</cell>
          <cell>Randomization - the explanatory variable (or treatment) being shuffled (or permuted) across the response variable (see Chapter <xref ref="sec-data-design" text="global" />)</cell>
        </row>
        <row bottom="medium">
          <cell>What other random processes can be approximated?</cell>
          <cell>Can also be used to test whether two variables from an observational study are related (see Chapter <xref ref="sec-inference-tables" text="global" />)</cell>
        </row>
      </tabular>
    </table>
  </subsection>

  <subsection xml:id="subsec-chp11-terms">
    <title>Terms</title>

    <p>The terms introduced in this chapter are presented in <xref ref="tbl-terms-chp-11" />. If you're not sure what some of these terms mean, we recommend you go back in the text and review their definitions. You should be able to easily spot them as <alert>bolded text</alert>.</p>

    <table xml:id="tbl-terms-chp-11">
      <title>Terms introduced in this chapter</title>
      <tabular>
        <row>
          <cell>hypothesis test</cell>
          <cell>independent</cell>
          <cell>randomization test</cell>
        </row>
        <row>
          <cell>permutation test</cell>
          <cell>point estimate</cell>
          <cell>null hypothesis</cell>
        </row>
        <row>
          <cell>alternative hypothesis</cell>
          <cell>simulation</cell>
          <cell>statistic</cell>
        </row>
        <row>
          <cell>test statistic</cell>
          <cell>statistical inference</cell>
          <cell>success</cell>
        </row>
        <row>
          <cell>p-value</cell>
          <cell>statistically discernible</cell>
          <cell>statistically significant</cell>
        </row>
        <row>
          <cell>significance level</cell>
          <cell>discernibility level</cell>
          <cell></cell>
        </row>
      </tabular>
    </table>
  </subsection>
</section>

<section xml:id="sec-chp11-exercises">
  <title>Exercises</title>

  <p>Answers to odd-numbered exercises can be found in <xref ref="sec-exercise-solutions-11" />.</p>

  <exercise xml:id="ex-parameter-prop-mean-i">
    <statement>
      <p><alert>Identify the parameter, I.</alert> For each of the following situations, state whether the parameter of interest is a mean or a proportion. It may be helpful to examine whether individual responses are numerical or categorical.</p>
      <p><ol>
        <li>In a survey, 100 college students are asked how many hours per week they spend on the Internet.</li>
        <li>In a survey, 100 college students are asked: <q>What percentage of the time you spend on the Internet is part of your course work?</q></li>
        <li>In a survey, 100 college students are asked whether they cited information from Wikipedia in their papers.</li>
        <li>In a survey, 100 college students are asked what percentage of their total weekly spending is on alcoholic beverages.</li>
        <li>In a sample of 100 recent college graduates, it is found that 85 percent expect to get a job within one year of their graduation date.</li>
      </ol></p>
    </statement>
  </exercise>

  <exercise xml:id="ex-parameter-prop-mean-ii">
    <statement>
      <p><alert>Identify the parameter, II.</alert> For each of the following situations, state whether the parameter of interest is a mean or a proportion.</p>
      <p><ol>
        <li>A poll shows that 64% of Americans personally worry a great deal about federal spending and the budget deficit.</li>
        <li>A survey reports that local TV news has shown a 17% increase in revenue within a two year period while newspaper revenues decreased by 6.4% during this time period.</li>
        <li>In a survey, high school and college students are asked whether they use geolocation services on their smart phones.</li>
        <li>In a survey, smart phone users are asked whether they use a web-based taxi service.</li>
        <li>In a survey, smart phone users are asked how many times they used a web-based taxi service over the last year.</li>
      </ol></p>
    </statement>
  </exercise>

  <exercise xml:id="ex-null-alt-hypotheses">
    <statement>
      <p><alert>Hypotheses.</alert> For each of the research statements below, note whether it represents a null hypothesis claim or an alternative hypothesis claim.</p>
      <p><ol>
        <li>The number of hours that grade-school children spend doing homework predicts their future success on standardized tests.</li>
        <li>King cheetahs on average run the same speed as standard spotted cheetahs.</li>
        <li>For a particular student, the probability of correctly answering a 5-option multiple choice test is larger than 0.2 (i.e., better than guessing).</li>
        <li>The mean length of African elephant tusks has changed over the last 100 years.</li>
        <li>The risk of facial clefts is equal for babies born to mothers who take folic acid supplements compared with those from mothers who do not.</li>
        <li>Caffeine intake during pregnancy affects mean birth weight.</li>
        <li>The probability of getting in a car accident is the same if using a cell phone than if not using a cell phone.</li>
      </ol></p>
    </statement>
  </exercise>

  <exercise xml:id="ex-true-null-hypothesis">
    <statement>
      <p><alert>True null hypothesis.</alert> Unbeknownst to you, let's say that the null hypothesis is actually true in the population. You plan to run a study anyway.</p>
      <p><ol>
        <li>If the level of discernibility you choose (i.e., the cutoff for your p-value) is 0.05, how likely is it that you will mistakenly reject the null hypothesis?</li>
        <li>If the level of discernibility you choose (i.e., the cutoff for your p-value) is 0.01, how likely is it that you will mistakenly reject the null hypothesis?</li>
        <li>If the level of discernibility you choose (i.e., the cutoff for your p-value) is 0.10, how likely is it that you will mistakenly reject the null hypothesis?</li>
      </ol></p>
    </statement>
  </exercise>

  <exercise xml:id="ex-identify-hypotheses-i">
    <statement>
      <p><alert>Identify hypotheses, I.</alert> Write the null and alternative hypotheses in words and then symbols for each of the following situations.</p>
      <p><ol>
        <li>New York is known as <q>the city that never sleeps</q>. A random sample of 25 New Yorkers were asked how much sleep they get per night. Do these data provide convincing evidence that New Yorkers on average sleep less than 8 hours a night?</li>
        <li>Employers at a firm are worried about the effect of March Madness, a basketball championship held each spring in the US, on employee productivity. They estimate that on a regular business day employees spend on average 15 minutes of company time checking personal email, making personal phone calls, etc. They also collect data on how much company time employees spend on such non-business activities during March Madness. They want to determine if these data provide convincing evidence that employee productivity decreases during March Madness.</li>
      </ol></p>
    </statement>
  </exercise>

  <exercise xml:id="ex-identify-hypotheses-ii">
    <statement>
      <p><alert>Identify hypotheses, II.</alert> Write the null and alternative hypotheses in words and using symbols for each of the following situations.</p>
      <p><ol>
        <li>Since 2008, chain restaurants in California have been required to display calorie counts of each menu item. Prior to menus displaying calorie counts, the average calorie intake of diners at a restaurant was 1100 calories. After calorie counts started to be displayed on menus, a nutritionist collected data on the number of calories consumed at this restaurant from a random sample of diners. Do these data provide convincing evidence of a difference in the average calorie intake of a diners at this restaurant?</li>
        <li>Based on the performance of those who took the GRE exam between July 1, 2004 and June 30, 2007, the average Verbal Reasoning score was calculated to be 462. In 2021 the average verbal score was slightly higher. Do these data provide convincing evidence that the average GRE Verbal Reasoning score has changed since 2021?</li>
      </ol></p>
    </statement>
  </exercise>

  <exercise xml:id="ex-avandia">
    <statement>
      <p><alert>Side effects of Avandia.</alert> Rosiglitazone is the active ingredient in the controversial type 2 diabetes medicine Avandia and has been linked to an increased risk of serious cardiovascular problems such as stroke, heart failure, and death. A common alternative treatment is Pioglitazone, the active ingredient in a diabetes medicine called Actos. In a nationwide retrospective observational study of 227,571 Medicare beneficiaries aged 65 years or older, it was found that 2,593 of the 67,593 patients using Rosiglitazone and 5,386 of the 159,978 using Pioglitazone had serious cardiovascular problems. These data are summarized in the contingency table below.<fn>The <url href="http://openintrostat.github.io/openintro/reference/avandia.html"><c>avandia</c></url> data used in this exercise can be found in the <url href="http://openintrostat.github.io/openintro"><alert>openintro</alert></url> R package.</fn> <xref ref="biblio-Graham-2010" /></p>

      <table xml:id="tbl-avandia-data">
        <title>Avandia study data</title>
        <tabular halign="center">
          <row header="yes" bottom="medium">
            <cell>Treatment</cell>
            <cell>Yes</cell>
            <cell>No</cell>
            <cell>Total</cell>
          </row>
          <row>
            <cell>Rosiglitazone</cell>
            <cell>2,593</cell>
            <cell>65,000</cell>
            <cell>67,593</cell>
          </row>
          <row>
            <cell>Pioglitazone</cell>
            <cell>5,386</cell>
            <cell>154,592</cell>
            <cell>159,978</cell>
          </row>
          <row bottom="medium">
            <cell>Total</cell>
            <cell>7,979</cell>
            <cell>219,592</cell>
            <cell>227,571</cell>
          </row>
        </tabular>
      </table>

      <p><ol>
        <li>Determine if each of the following statements is true or false. If false, explain why. <em>Be careful:</em> The reasoning may be wrong even if the statement's conclusion is correct. In such cases, the statement should be considered false.
          <ol>
            <li>Since more patients on Pioglitazone had cardiovascular problems (5,386 vs. 2,593), we can conclude that the rate of cardiovascular problems for those on a Pioglitazone treatment is higher.</li>
            <li>The data suggest that diabetic patients who are taking Rosiglitazone are more likely to have cardiovascular problems since the rate of incidence was (2,593 / 67,593 = 0.038) 3.8% for patients on this treatment, while it was only (5,386 / 159,978 = 0.034) 3.4% for patients on Pioglitazone.</li>
            <li>The fact that the rate of incidence is higher for the Rosiglitazone group proves that Rosiglitazone causes serious cardiovascular problems.</li>
            <li>Based on the information provided so far, we cannot tell if the difference between the rates of incidences is due to a relationship between the two variables or due to chance.</li>
          </ol>
        </li>
        <li>What proportion of all patients had cardiovascular problems?</li>
        <li>If the type of treatment and having cardiovascular problems were independent, how many patients in the Rosiglitazone group would we expect to have had cardiovascular problems?</li>
        <li>We can investigate the relationship between outcome and treatment in this study using a randomization technique. While in reality we would carry out the simulations required for randomization using statistical software, suppose we actually simulate using index cards. In order to simulate from the independence model, which states that the outcomes were independent of the treatment, we write whether each patient had a cardiovascular problem on cards, shuffled all the cards together, then deal them into two groups of size 67,593 and 159,978. We repeat this simulation 100 times and each time record the difference between the proportions of cards that say <q>Yes</q> in the Rosiglitazone and Pioglitazone groups. Use the histogram of these differences in proportions to answer the following questions.
          <ol>
            <li>What are the claims being tested?</li>
            <li>Compared to the number calculated in part (b), which would provide more support for the alternative hypothesis, <em>higher</em> or <em>lower</em> proportion of patients with cardiovascular problems in the Rosiglitazone group?</li>
            <li>What do the simulation results suggest about the relationship between taking Rosiglitazone and having cardiovascular problems in diabetic patients?</li>
          </ol>
        </li>
      </ol></p>

      <figure xml:id="fig-avandia-sim">
        <caption>100 differences in randomized proportions</caption>
        <image source="images/fig-avandia-sim-1.png" width="70%" />
      </figure>
    </statement>
  </exercise>

  <exercise xml:id="ex-heart-transplants">
    <statement>
      <p><alert>Heart transplants.</alert> The Stanford University Heart Transplant Study was conducted to determine whether an experimental heart transplant program increased lifespan. Each patient entering the program was designated an official heart transplant candidate, meaning that they were gravely ill and would most likely benefit from a new heart. Some patients got a transplant and some did not. The variable <c>transplant</c> indicates which group the patients were in; patients in the treatment group got a transplant and those in the control group did not. Of the 34 patients in the control group, 30 died. Of the 69 people in the treatment group, 45 died. Another variable called <c>survived</c> was used to indicate whether the patient was alive at the end of the study.<fn>The <url href="http://openintrostat.github.io/openintro/reference/heart_transplant.html"><c>heart_transplant</c></url> data used in this exercise can be found in the <url href="http://openintrostat.github.io/openintro"><alert>openintro</alert></url> R package.</fn> <xref ref="biblio-Turnbull-1974" /></p>

      <figure xml:id="fig-heart-transplant-plots">
        <caption>Visualizations for the heart transplant study</caption>
        <image source="images/fig-heart-transplant-plots-1.png" width="90%" />
      </figure>

      <p><ol>
        <li>Does the stacked bar plot indicate that survival is independent of whether the patient got a transplant? Explain your reasoning.</li>
        <li>What do the box plots suggest about the efficacy of heart transplants.</li>
        <li>What proportions of patients in the treatment and control groups died?</li>
        <li>One approach for investigating whether the treatment is discernably effective is randomization testing.
          <ol>
            <li>What are the claims being tested?</li>
            <li>The paragraph below describes the set up for a randomization test, if we were to do it without using statistical software. Fill in the blanks with a number or phrase.
              <blockquote>
                <p>We write <em>alive</em> on _______ cards representing patients who were alive at the end of the study, and <em>deceased</em> on _______ cards representing patients who were not. Then, we shuffle these cards and split them into two groups: one group of size _______ representing treatment, and another group of size _______ representing control. We calculate the difference between the proportion of <em>deceased</em> cards in the treatment and control groups (treatment - control) and record this value. We repeat this 100 times to build a distribution centered at _______. Lastly, we calculate the proportion of simulations where the simulated differences in proportions are _______. If this proportion is low, we conclude that it is unlikely to have observed such an outcome by chance and that the null hypothesis should be rejected in favor of the alternative.</p>
              </blockquote>
            </li>
            <li>What do the simulation results shown below suggest about the effectiveness of heart transplants?</li>
          </ol>
        </li>
      </ol></p>

      <figure xml:id="fig-heart-transplant-sim">
        <caption>100 differences in randomized proportions of deceased (treatment - control)</caption>
        <image source="images/fig-heart-transplant-sim-1.png" width="70%" />
      </figure>
    </statement>
  </exercise>

</section>

</chapter>
